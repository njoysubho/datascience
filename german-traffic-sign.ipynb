{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms \nimport torchvision.transforms as T\nfrom torchvision.models import efficientnet_b0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-24T06:12:36.118814Z","iopub.execute_input":"2023-07-24T06:12:36.119278Z","iopub.status.idle":"2023-07-24T06:12:36.125654Z","shell.execute_reply.started":"2023-07-24T06:12:36.119237Z","shell.execute_reply":"2023-07-24T06:12:36.124462Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class GermanTraffic(Dataset):\n    def __init__(self, root_dir, transform=None, train=True, verify_ratio=0.2):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.categories = os.listdir(root_dir)\n        self.category_mapping = {category: int(category) for idx, category in enumerate(self.categories)}\n        self.filepaths = self._get_filepaths()\n\n        if train:\n            self.filepaths = self._split_data(verify_ratio)[0]\n        else:\n            self.filepaths = self._split_data(verify_ratio)[1]\n\n    def __len__(self):\n        return len(self.filepaths)\n\n    def __getitem__(self, idx):\n        filepath, label = self.filepaths[idx]\n        image = Image.open(filepath).convert('RGB')\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n    def _get_filepaths(self):\n        filepaths = []\n        for category in self.categories:\n            category_folder = os.path.join(self.root_dir, category)\n            image_files = os.listdir(category_folder)\n            for image_file in image_files:\n                image_path = os.path.join(category_folder, image_file)\n                filepaths.append((image_path, self.category_mapping[category]))\n\n        return filepaths\n\n    def _split_data(self, verify_ratio):\n        filepaths_train, filepaths_verify = train_test_split(self.filepaths, test_size=verify_ratio)\n        return filepaths_train, filepaths_verify\n","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:36.127412Z","iopub.execute_input":"2023-07-24T06:12:36.128229Z","iopub.status.idle":"2023-07-24T06:12:36.141081Z","shell.execute_reply.started":"2023-07-24T06:12:36.128197Z","shell.execute_reply":"2023-07-24T06:12:36.140024Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.CenterCrop((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntrain_ds = GermanTraffic('../input/acc-german-traffic-sign-classification/GTSRB_Challenge/train/',transform=transform)\nvalid_ds = GermanTraffic('../input/acc-german-traffic-sign-classification/GTSRB_Challenge/train/',transform=transform,train=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:36.142301Z","iopub.execute_input":"2023-07-24T06:12:36.142927Z","iopub.status.idle":"2023-07-24T06:12:54.101234Z","shell.execute_reply.started":"2023-07-24T06:12:36.142895Z","shell.execute_reply":"2023-07-24T06:12:54.100249Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds,batch_size=64)\nvalid_dl = DataLoader(valid_ds,batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:54.103996Z","iopub.execute_input":"2023-07-24T06:12:54.104352Z","iopub.status.idle":"2023-07-24T06:12:54.109864Z","shell.execute_reply.started":"2023-07-24T06:12:54.104318Z","shell.execute_reply":"2023-07-24T06:12:54.108352Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = efficientnet_b0(num_classes=43)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:54.111164Z","iopub.execute_input":"2023-07-24T06:12:54.111563Z","iopub.status.idle":"2023-07-24T06:12:54.323668Z","shell.execute_reply.started":"2023-07-24T06:12:54.111531Z","shell.execute_reply":"2023-07-24T06:12:54.322619Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0')\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:54.325188Z","iopub.execute_input":"2023-07-24T06:12:54.325553Z","iopub.status.idle":"2023-07-24T06:12:57.130050Z","shell.execute_reply.started":"2023-07-24T06:12:54.325520Z","shell.execute_reply":"2023-07-24T06:12:57.129061Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(train_dl)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:22:04.263051Z","iopub.execute_input":"2023-07-24T06:22:04.263911Z","iopub.status.idle":"2023-07-24T06:22:04.273757Z","shell.execute_reply.started":"2023-07-24T06:22:04.263865Z","shell.execute_reply":"2023-07-24T06:22:04.272773Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"491"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\n# Define your loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Define your optimizer\nnum_epochs = 10\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer,max_lr=0.001,epochs=num_epochs,steps_per_epoch=64)\nnum_epochs = 10\n# Training loop\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    for inputs, labels in train_dl:\n        optimizer.zero_grad()\n        inputs=inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        running_loss += loss.item()\n    avg_train_loss = running_loss / len(train_dl)\n\n    # Validation phase\n    model.eval()  # Set the model to evaluation mode\n    running_val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in valid_dl:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    avg_val_loss = running_val_loss / len(valid_dl)\n    val_accuracy = correct / total\n\n    # Print average loss and accuracy for the epoch\n    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f} | Val Accuracy = {val_accuracy:.2%}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:26:23.351523Z","iopub.execute_input":"2023-07-24T06:26:23.351914Z","iopub.status.idle":"2023-07-24T06:34:58.618866Z","shell.execute_reply.started":"2023-07-24T06:26:23.351880Z","shell.execute_reply":"2023-07-24T06:34:58.617628Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss = 2.5729 | Val Loss = 0.9379 | Val Accuracy = 70.79%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     29\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dl)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:150\u001b[0m, in \u001b[0;36mLRScheduler.step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 150\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(EPOCH_DEPRECATION_WARNING, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:1706\u001b[0m, in \u001b[0;36mOneCycleLR.get_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1703\u001b[0m step_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_epoch\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step_num \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_steps:\n\u001b[0;32m-> 1706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m times. The specified number of total steps is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1707\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(step_num, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_steps))\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m   1710\u001b[0m     start_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","\u001b[0;31mValueError\u001b[0m: Tried to step 641 times. The specified number of total steps is 640"],"ename":"ValueError","evalue":"Tried to step 641 times. The specified number of total steps is 640","output_type":"error"}]},{"cell_type":"code","source":"save_path = \"gts_state_dict.pth\"\n\n# Save only the model's state_dict (learned parameters)\ntorch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:57.585531Z","iopub.status.idle":"2023-07-24T06:12:57.586025Z","shell.execute_reply.started":"2023-07-24T06:12:57.585789Z","shell.execute_reply":"2023-07-24T06:12:57.585811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/acc-german-traffic-sign-classification/GTSRB_Challenge/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:57.587510Z","iopub.status.idle":"2023-07-24T06:12:57.588332Z","shell.execute_reply.started":"2023-07-24T06:12:57.588081Z","shell.execute_reply":"2023-07-24T06:12:57.588104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['ClassId']==2]\ndf","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:57.589681Z","iopub.status.idle":"2023-07-24T06:12:57.590471Z","shell.execute_reply.started":"2023-07-24T06:12:57.590235Z","shell.execute_reply":"2023-07-24T06:12:57.590258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nimport torch\nimport torchvision.transforms as transforms\n\n# Assuming you have a trained model loaded in the 'model' variable\n\n# Set the path to the submission.csv file and the test folder\nsubmission_file = \"../input/acc-german-traffic-sign-classification/GTSRB_Challenge/sample_submission.csv\"\ntest_folder = \"../input/acc-german-traffic-sign-classification/GTSRB_Challenge/test\"\n\n# Function to load and preprocess the image\ndef load_image(image_path):\n    image = Image.open(image_path)\n    transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.CenterCrop((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    return transform(image).unsqueeze(0)\n\n# Load the submission.csv file\nsubmission_df = pd.read_csv(submission_file)\n\n# Initialize lists to store the predictions and file names\npredictions = []\nfile_names = []\n#trainedModel = resnet.resnet34(num_classes=43)\n\n    # Load the state dictionary into the model\n#trainedModel.load_state_dict(torch.load('../working/gts_state_dict.pth'))\n\n# Loop through the submission dataframe\nfor index, row in submission_df.iterrows():\n    file_name = row['Filename']\n    image_path = os.path.join(test_folder, file_name)\n\n    # Ensure the image file exists\n    if not os.path.exists(image_path):\n        print(f\"Image not found: {file_name}\")\n        continue\n\n    # Load and preprocess the image\n    image_tensor = load_image(image_path)\n    \n    image_tensor = image_tensor.to(device)\n    # Make a prediction using the trained model\n    with torch.no_grad():\n        model.eval()  # Set the model to evaluation mode\n        output = model(image_tensor)\n        _, predicted_class = torch.max(output, 1)\n        predictions.append(predicted_class.item())\n        file_names.append(file_name)\n\n# Create a new DataFrame to store the predictions\npredictions_df = pd.DataFrame({'Filename': file_names, 'ClassId': predictions})\n\n# Save the predictions to a new CSV file\npredictions_df.to_csv('submission.csv', index=False)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:57.591932Z","iopub.status.idle":"2023-07-24T06:12:57.592552Z","shell.execute_reply.started":"2023-07-24T06:12:57.592309Z","shell.execute_reply":"2023-07-24T06:12:57.592332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../working/submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-24T06:12:57.593927Z","iopub.status.idle":"2023-07-24T06:12:57.594725Z","shell.execute_reply.started":"2023-07-24T06:12:57.594467Z","shell.execute_reply":"2023-07-24T06:12:57.594489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
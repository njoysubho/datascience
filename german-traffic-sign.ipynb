{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms \nimport torchvision.transforms as T\nfrom torchvision.models import efficientnet_b0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-23T07:19:04.042530Z","iopub.execute_input":"2023-07-23T07:19:04.043215Z","iopub.status.idle":"2023-07-23T07:19:04.049132Z","shell.execute_reply.started":"2023-07-23T07:19:04.043181Z","shell.execute_reply":"2023-07-23T07:19:04.047914Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class GermanTraffic(Dataset):\n    def __init__(self, root_dir, transform=None, train=True, verify_ratio=0.2):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.categories = os.listdir(root_dir)\n        self.category_mapping = {category: int(category) for idx, category in enumerate(self.categories)}\n        self.filepaths = self._get_filepaths()\n\n        if train:\n            self.filepaths = self._split_data(verify_ratio)[0]\n        else:\n            self.filepaths = self._split_data(verify_ratio)[1]\n\n    def __len__(self):\n        return len(self.filepaths)\n\n    def __getitem__(self, idx):\n        filepath, label = self.filepaths[idx]\n        image = Image.open(filepath).convert('RGB')\n\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n    def _get_filepaths(self):\n        filepaths = []\n        for category in self.categories:\n            category_folder = os.path.join(self.root_dir, category)\n            image_files = os.listdir(category_folder)\n            for image_file in image_files:\n                image_path = os.path.join(category_folder, image_file)\n                filepaths.append((image_path, self.category_mapping[category]))\n\n        return filepaths\n\n    def _split_data(self, verify_ratio):\n        filepaths_train, filepaths_verify = train_test_split(self.filepaths, test_size=verify_ratio)\n        return filepaths_train, filepaths_verify\n","metadata":{"execution":{"iopub.status.busy":"2023-07-23T06:30:29.146284Z","iopub.execute_input":"2023-07-23T06:30:29.146786Z","iopub.status.idle":"2023-07-23T06:30:29.157537Z","shell.execute_reply.started":"2023-07-23T06:30:29.146759Z","shell.execute_reply":"2023-07-23T06:30:29.156385Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.CenterCrop((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntrain_ds = GermanTraffic('../input/acc-german-traffic-sign-classification/GTSRB_Challenge/train/',transform=transform)\nvalid_ds = GermanTraffic('../input/acc-german-traffic-sign-classification/GTSRB_Challenge/train/',transform=transform,train=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T06:30:29.159105Z","iopub.execute_input":"2023-07-23T06:30:29.159771Z","iopub.status.idle":"2023-07-23T06:30:33.143845Z","shell.execute_reply.started":"2023-07-23T06:30:29.159738Z","shell.execute_reply":"2023-07-23T06:30:33.142863Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(train_ds,batch_size=64)\nvalid_dl = DataLoader(valid_ds,batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T06:30:33.146388Z","iopub.execute_input":"2023-07-23T06:30:33.146768Z","iopub.status.idle":"2023-07-23T06:30:33.153368Z","shell.execute_reply.started":"2023-07-23T06:30:33.146733Z","shell.execute_reply":"2023-07-23T06:30:33.152335Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = efficientnet_b0(num_classes=43)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:23:02.432192Z","iopub.execute_input":"2023-07-23T07:23:02.432755Z","iopub.status.idle":"2023-07-23T07:23:02.531481Z","shell.execute_reply.started":"2023-07-23T07:23:02.432716Z","shell.execute_reply":"2023-07-23T07:23:02.530510Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0')\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:23:13.208831Z","iopub.execute_input":"2023-07-23T07:23:13.209187Z","iopub.status.idle":"2023-07-23T07:23:13.232809Z","shell.execute_reply.started":"2023-07-23T07:23:13.209159Z","shell.execute_reply":"2023-07-23T07:23:13.231842Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\n# Define your loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Define your optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nnum_epochs = 10\n# Training loop\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()  # Set the model to training mode\n    running_loss = 0.0\n    for inputs, labels in train_dl:\n        optimizer.zero_grad()\n        inputs=inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    avg_train_loss = running_loss / len(train_dl)\n\n    # Validation phase\n    model.eval()  # Set the model to evaluation mode\n    running_val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in valid_dl:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    avg_val_loss = running_val_loss / len(valid_dl)\n    val_accuracy = correct / total\n\n    # Print average loss and accuracy for the epoch\n    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f} | Val Accuracy = {val_accuracy:.2%}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:23:16.132180Z","iopub.execute_input":"2023-07-23T07:23:16.133202Z","iopub.status.idle":"2023-07-23T07:58:41.150762Z","shell.execute_reply.started":"2023-07-23T07:23:16.133160Z","shell.execute_reply":"2023-07-23T07:58:41.149723Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss = 3.1658 | Val Loss = 2.1780 | Val Accuracy = 40.98%\nEpoch 2: Train Loss = 1.5608 | Val Loss = 0.7329 | Val Accuracy = 81.00%\nEpoch 3: Train Loss = 0.6597 | Val Loss = 0.7410 | Val Accuracy = 84.86%\nEpoch 4: Train Loss = 0.3133 | Val Loss = 0.1631 | Val Accuracy = 97.64%\nEpoch 5: Train Loss = 0.1697 | Val Loss = 0.0716 | Val Accuracy = 98.56%\nEpoch 6: Train Loss = 0.1146 | Val Loss = 0.0547 | Val Accuracy = 98.83%\nEpoch 7: Train Loss = 0.0831 | Val Loss = 0.0179 | Val Accuracy = 99.53%\nEpoch 8: Train Loss = 0.0654 | Val Loss = 0.0082 | Val Accuracy = 99.78%\nEpoch 10: Train Loss = 0.0400 | Val Loss = 0.0045 | Val Accuracy = 99.92%\n","output_type":"stream"}]},{"cell_type":"code","source":"save_path = \"gts_state_dict.pth\"\n\n# Save only the model's state_dict (learned parameters)\ntorch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:58:50.699482Z","iopub.execute_input":"2023-07-23T07:58:50.699875Z","iopub.status.idle":"2023-07-23T07:58:50.785089Z","shell.execute_reply.started":"2023-07-23T07:58:50.699844Z","shell.execute_reply":"2023-07-23T07:58:50.783895Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/acc-german-traffic-sign-classification/GTSRB_Challenge/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:58:54.511817Z","iopub.execute_input":"2023-07-23T07:58:54.512186Z","iopub.status.idle":"2023-07-23T07:58:54.534005Z","shell.execute_reply.started":"2023-07-23T07:58:54.512157Z","shell.execute_reply":"2023-07-23T07:58:54.533039Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df = df[['ClassId']==43]","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:58:58.964324Z","iopub.execute_input":"2023-07-23T07:58:58.964726Z","iopub.status.idle":"2023-07-23T07:58:58.978416Z","shell.execute_reply.started":"2023-07-23T07:58:58.964693Z","shell.execute_reply":"2023-07-23T07:58:58.977246Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                     Filename  ClassId\n0      1558973073.8358536.ppm        1\n1      1558973073.8359206.ppm        1\n2      1558973073.8359365.ppm        1\n3      1558973073.8359509.ppm        1\n4      1558973073.8359642.ppm        1\n...                       ...      ...\n12625   1558973073.902373.ppm        1\n12626   1558973073.902377.ppm        1\n12627  1558973073.9023807.ppm        1\n12628  1558973073.9023848.ppm        1\n12629  1558973073.9023886.ppm        1\n\n[12630 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filename</th>\n      <th>ClassId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1558973073.8358536.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1558973073.8359206.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1558973073.8359365.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1558973073.8359509.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1558973073.8359642.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12625</th>\n      <td>1558973073.902373.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12626</th>\n      <td>1558973073.902377.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12627</th>\n      <td>1558973073.9023807.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12628</th>\n      <td>1558973073.9023848.ppm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12629</th>\n      <td>1558973073.9023886.ppm</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>12630 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nimport torch\nimport torchvision.transforms as transforms\n\n# Assuming you have a trained model loaded in the 'model' variable\n\n# Set the path to the submission.csv file and the test folder\nsubmission_file = \"../input/acc-german-traffic-sign-classification/GTSRB_Challenge/sample_submission.csv\"\ntest_folder = \"../input/acc-german-traffic-sign-classification/GTSRB_Challenge/test\"\n\n# Function to load and preprocess the image\ndef load_image(image_path):\n    image = Image.open(image_path)\n    transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.CenterCrop((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    return transform(image).unsqueeze(0)\n\n# Load the submission.csv file\nsubmission_df = pd.read_csv(submission_file)\n\n# Initialize lists to store the predictions and file names\npredictions = []\nfile_names = []\n#trainedModel = resnet.resnet34(num_classes=43)\n\n    # Load the state dictionary into the model\n#trainedModel.load_state_dict(torch.load('../working/gts_state_dict.pth'))\n\n# Loop through the submission dataframe\nfor index, row in submission_df.iterrows():\n    file_name = row['Filename']\n    image_path = os.path.join(test_folder, file_name)\n\n    # Ensure the image file exists\n    if not os.path.exists(image_path):\n        print(f\"Image not found: {file_name}\")\n        continue\n\n    # Load and preprocess the image\n    image_tensor = load_image(image_path)\n    \n    image_tensor = image_tensor.to(device)\n    # Make a prediction using the trained model\n    with torch.no_grad():\n        model.eval()  # Set the model to evaluation mode\n        output = model(image_tensor)\n        _, predicted_class = torch.max(output, 1)\n        predictions.append(predicted_class.item())\n        file_names.append(file_name)\n\n# Create a new DataFrame to store the predictions\npredictions_df = pd.DataFrame({'Filename': file_names, 'ClassId': predictions})\n\n# Save the predictions to a new CSV file\npredictions_df.to_csv('submission.csv', index=False)\n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:59:16.899136Z","iopub.execute_input":"2023-07-23T07:59:16.899517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../working/submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T07:05:53.262228Z","iopub.execute_input":"2023-07-23T07:05:53.262576Z","iopub.status.idle":"2023-07-23T07:05:53.280858Z","shell.execute_reply.started":"2023-07-23T07:05:53.262544Z","shell.execute_reply":"2023-07-23T07:05:53.279895Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
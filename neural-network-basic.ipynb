{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-09T07:03:10.431872Z","iopub.execute_input":"2023-07-09T07:03:10.432281Z","iopub.status.idle":"2023-07-09T07:03:10.437018Z","shell.execute_reply.started":"2023-07-09T07:03:10.432247Z","shell.execute_reply":"2023-07-09T07:03:10.436016Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"X= np.random.rand(4,50)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T07:04:33.751344Z","iopub.execute_input":"2023-07-09T07:04:33.752272Z","iopub.status.idle":"2023-07-09T07:04:33.757613Z","shell.execute_reply.started":"2023-07-09T07:04:33.752233Z","shell.execute_reply":"2023-07-09T07:04:33.756409Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"Y = np.random.choice([0,1],size=50*1)\nY=Y.reshape((1,50))","metadata":{"execution":{"iopub.status.busy":"2023-07-09T08:01:10.302506Z","iopub.execute_input":"2023-07-09T08:01:10.303515Z","iopub.status.idle":"2023-07-09T08:01:10.309872Z","shell.execute_reply.started":"2023-07-09T08:01:10.303463Z","shell.execute_reply":"2023-07-09T08:01:10.308842Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"We assume a 3 layer neural network with [4,4,1] nodes in layer respectively. ","metadata":{}},{"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1+np.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2023-07-09T07:58:19.355529Z","iopub.execute_input":"2023-07-09T07:58:19.355967Z","iopub.status.idle":"2023-07-09T07:58:19.361547Z","shell.execute_reply.started":"2023-07-09T07:58:19.355935Z","shell.execute_reply":"2023-07-09T07:58:19.360441Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n    return np.exp(x) / np.sum(np.exp(x), axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T07:58:19.930888Z","iopub.execute_input":"2023-07-09T07:58:19.931299Z","iopub.status.idle":"2023-07-09T07:58:19.939208Z","shell.execute_reply.started":"2023-07-09T07:58:19.931264Z","shell.execute_reply":"2023-07-09T07:58:19.938145Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def relu(x):\n    return np.maximum(0,x)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T07:58:20.733075Z","iopub.execute_input":"2023-07-09T07:58:20.733497Z","iopub.status.idle":"2023-07-09T07:58:20.738465Z","shell.execute_reply.started":"2023-07-09T07:58:20.733461Z","shell.execute_reply":"2023-07-09T07:58:20.737239Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"In the below I am initializing Ws and bs. Most confusing part here is dimension , I am following Andrew Ng's approach \nX= [numOfFeature,numOfSamples] -> so if we have 4 features and we have 50 samples then X is of shape (4,50)\nW = [numOfNodesInCurrentLayer, numNodesPreviousLayer] ->  for W1 which is the first layer previous layer is input or X  ","metadata":{}},{"cell_type":"code","source":"numOfFeatures = X.shape[0]\nnumOfSamples = X.shape[1]\nW1 = np.random.randn(4,numOfFeatures)\nb1 = np.zeros((4,1))\nW2 = np.random.randn(4,4)\nb2 = np.zeros((4,1))\nW3 = np.random.randn(1,4)\nb3 = np.zeros((1,1))\nZ1 = np.dot(W1,X)+b1\nA1 = relu(Z1)\nZ2 = np.dot(W2,A1)+b2\nA2 = relu(Z2)\nZ3 = np.dot(W3,A2)+b3\nA3 = sigmoid(Z3)\nA3.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-09T07:58:22.279674Z","iopub.execute_input":"2023-07-09T07:58:22.280101Z","iopub.status.idle":"2023-07-09T07:58:22.292108Z","shell.execute_reply.started":"2023-07-09T07:58:22.280068Z","shell.execute_reply":"2023-07-09T07:58:22.290993Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"(1, 50)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see how different our predicted output is from actual output. Our objective is to become as close as possible to actual output.\nObserving the below values show us that we are way off. \nWe need some measurement of how bad our prediction is , this is call a loss function. \nloss function I chose here is negative log loss. \nLoss = -1/m\\sum(ylog(yhat)+(1-y)log(1-yhat))\nlook at the minus sign in front. In order to minimise the loss we need to maximise the function","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"Y.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-09T08:01:13.759347Z","iopub.execute_input":"2023-07-09T08:01:13.760157Z","iopub.status.idle":"2023-07-09T08:01:13.766363Z","shell.execute_reply.started":"2023-07-09T08:01:13.760116Z","shell.execute_reply":"2023-07-09T08:01:13.765337Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"(1, 50)"},"metadata":{}}]},{"cell_type":"code","source":"A3","metadata":{"execution":{"iopub.status.busy":"2023-07-09T07:58:30.180269Z","iopub.execute_input":"2023-07-09T07:58:30.180916Z","iopub.status.idle":"2023-07-09T07:58:30.188739Z","shell.execute_reply.started":"2023-07-09T07:58:30.180883Z","shell.execute_reply":"2023-07-09T07:58:30.187679Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"array([[0.88610478, 0.90568179, 0.95004877, 0.74066875, 0.98194908,\n        0.87833221, 0.90014556, 0.79083374, 0.77426063, 0.40530462,\n        0.90781307, 0.93559632, 0.93031291, 0.66938982, 0.47530203,\n        0.86100468, 0.68102781, 0.4399386 , 0.98203834, 0.50536094,\n        0.87715414, 0.92817176, 0.69183932, 0.61079734, 0.68567306,\n        0.9924664 , 0.97543682, 0.90903375, 0.64646006, 0.89773504,\n        0.69891706, 0.38478819, 0.76477951, 0.73620731, 0.97481131,\n        0.49563457, 0.56935859, 0.91393433, 0.74354874, 0.63035052,\n        0.49251099, 0.66806692, 0.90877976, 0.45052858, 0.54718035,\n        0.85717824, 0.81716687, 0.99194412, 0.95422587, 0.99378294]])"},"metadata":{}}]},{"cell_type":"code","source":"def negative_log_loss(y,yhat):\n    m = y.shape[1]\n    return -1/m*np.sum(y*np.log(yhat)+(1-y)*np.log(1-yhat))","metadata":{"execution":{"iopub.status.busy":"2023-07-09T07:46:59.317607Z","iopub.execute_input":"2023-07-09T07:46:59.318226Z","iopub.status.idle":"2023-07-09T07:46:59.323704Z","shell.execute_reply.started":"2023-07-09T07:46:59.318192Z","shell.execute_reply":"2023-07-09T07:46:59.322656Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"loss = negative_log_loss(Y,A3)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T08:02:10.969632Z","iopub.execute_input":"2023-07-09T08:02:10.970060Z","iopub.status.idle":"2023-07-09T08:02:10.975663Z","shell.execute_reply.started":"2023-07-09T08:02:10.970027Z","shell.execute_reply":"2023-07-09T08:02:10.974328Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def sigmoid_backward(Z): \n    s = 1/(1+np.exp(-Z))\n    return s * (1-s)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T08:10:16.525184Z","iopub.execute_input":"2023-07-09T08:10:16.525608Z","iopub.status.idle":"2023-07-09T08:10:16.531427Z","shell.execute_reply.started":"2023-07-09T08:10:16.525575Z","shell.execute_reply":"2023-07-09T08:10:16.530294Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"dA3 = - (np.divide(Y, A3) - np.divide(1 - Y, 1 - A3))\ndZ3 = dA3*A","metadata":{"execution":{"iopub.status.busy":"2023-07-09T08:03:09.432150Z","iopub.execute_input":"2023-07-09T08:03:09.432532Z","iopub.status.idle":"2023-07-09T08:03:09.437625Z","shell.execute_reply.started":"2023-07-09T08:03:09.432504Z","shell.execute_reply":"2023-07-09T08:03:09.436859Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"dA3","metadata":{"execution":{"iopub.status.busy":"2023-07-09T08:03:16.143701Z","iopub.execute_input":"2023-07-09T08:03:16.144525Z","iopub.status.idle":"2023-07-09T08:03:16.152187Z","shell.execute_reply.started":"2023-07-09T08:03:16.144484Z","shell.execute_reply":"2023-07-09T08:03:16.150904Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"array([[ -1.12853471,  10.60240691,  20.01952829,   3.85607204,\n         55.39883367,   8.21910238,  -1.11093144,  -1.26448828,\n          4.4298874 ,   1.68153316,  -1.10154836,  -1.06883704,\n         14.34985987,   3.02471027,   1.90585835,   7.19448704,\n          3.13506957,   1.7855185 ,  55.67413119,  -1.9787837 ,\n          8.14028249,  13.92210147,   3.24506037,  -1.63720424,\n         -1.45842101,  -1.00759078,  -1.02518172,  -1.10006916,\n          2.82853474,  -1.11391442,   3.32134396,   1.62545645,\n         -1.30756641,  -1.35831306,  39.70036273,  -2.0176155 ,\n          2.3221176 ,  11.61903473,  -1.34490175,  -1.58641894,\n          1.97048602,   3.01265541,  10.96247953,  -2.21961504,\n          2.20838472,   7.00173441,  -1.22374027, 124.13291171,\n         21.84640191,  -1.00625595]])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport category_encoders\nfrom sklearn.preprocessing import OrdinalEncoder,LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nimport category_encoders as ce\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-12T05:44:08.892223Z","iopub.execute_input":"2022-09-12T05:44:08.893326Z","iopub.status.idle":"2022-09-12T05:44:08.899091Z","shell.execute_reply.started":"2022-09-12T05:44:08.893274Z","shell.execute_reply":"2022-09-12T05:44:08.898126Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"car_data_df = pd.read_csv('../input/car-evaluation-data-set/car_evaluation.csv')\ncar_data_df=car_data_df.rename(columns={'vhigh':'buying_price','vhigh.1':'maint','2':'num_doors','2.1':'num_persons','small':'lug_boot','low':'safety','unacc':'decision'})","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:07:31.795643Z","iopub.execute_input":"2022-09-12T05:07:31.796040Z","iopub.status.idle":"2022-09-12T05:07:31.809598Z","shell.execute_reply.started":"2022-09-12T05:07:31.796010Z","shell.execute_reply":"2022-09-12T05:07:31.808565Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"features = ['buying_price','maint','num_doors','num_persons','lug_boot','safety']\nX = car_data_df[features]","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:39:14.223528Z","iopub.execute_input":"2022-09-12T05:39:14.223912Z","iopub.status.idle":"2022-09-12T05:39:14.230830Z","shell.execute_reply.started":"2022-09-12T05:39:14.223881Z","shell.execute_reply":"2022-09-12T05:39:14.229522Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"target = ['decision']\nY = car_data_df[target]","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:39:16.033707Z","iopub.execute_input":"2022-09-12T05:39:16.034422Z","iopub.status.idle":"2022-09-12T05:39:16.040691Z","shell.execute_reply.started":"2022-09-12T05:39:16.034369Z","shell.execute_reply":"2022-09-12T05:39:16.039573Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,Y_train,Y_test= train_test_split(X,Y,train_size=0.9)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:39:17.176557Z","iopub.execute_input":"2022-09-12T05:39:17.176970Z","iopub.status.idle":"2022-09-12T05:39:17.183264Z","shell.execute_reply.started":"2022-09-12T05:39:17.176934Z","shell.execute_reply":"2022-09-12T05:39:17.182473Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"ordinal_encoder = ce.OrdinalEncoder(cols=['buying_price', 'maint', 'num_doors', 'num_persons', 'lug_boot', 'safety'])\nX_train = ordinal_encoder.fit_transform(X_train)\nX_test = ordinal_encoder.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:39:30.987816Z","iopub.execute_input":"2022-09-12T05:39:30.988217Z","iopub.status.idle":"2022-09-12T05:39:31.033968Z","shell.execute_reply.started":"2022-09-12T05:39:30.988171Z","shell.execute_reply":"2022-09-12T05:39:31.033120Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"clf = DecisionTreeClassifier(criterion='gini',max_depth=10)\nclf.fit(X_train,Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:42:58.335191Z","iopub.execute_input":"2022-09-12T05:42:58.335597Z","iopub.status.idle":"2022-09-12T05:42:58.349357Z","shell.execute_reply.started":"2022-09-12T05:42:58.335568Z","shell.execute_reply":"2022-09-12T05:42:58.348101Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"DecisionTreeClassifier(max_depth=10)"},"metadata":{}}]},{"cell_type":"code","source":"Y_pred = clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:42:37.563724Z","iopub.execute_input":"2022-09-12T05:42:37.564110Z","iopub.status.idle":"2022-09-12T05:42:37.570616Z","shell.execute_reply.started":"2022-09-12T05:42:37.564078Z","shell.execute_reply":"2022-09-12T05:42:37.569408Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"accuracy_score(Y_test,Y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:42:38.699315Z","iopub.execute_input":"2022-09-12T05:42:38.700633Z","iopub.status.idle":"2022-09-12T05:42:38.709196Z","shell.execute_reply.started":"2022-09-12T05:42:38.700573Z","shell.execute_reply":"2022-09-12T05:42:38.708051Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"0.9710982658959537"},"metadata":{}}]},{"cell_type":"code","source":"cm = confusion_matrix(Y_test, Y_pred)\n\nprint('Confusion matrix\\n\\n', cm)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:44:35.318491Z","iopub.execute_input":"2022-09-12T05:44:35.318880Z","iopub.status.idle":"2022-09-12T05:44:35.327743Z","shell.execute_reply.started":"2022-09-12T05:44:35.318850Z","shell.execute_reply":"2022-09-12T05:44:35.326843Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Confusion matrix\n\n [[ 45   0   2   1]\n [  1   7   0   1]\n [  0   0 112   0]\n [  0   0   0   4]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-09-12T05:45:08.416807Z","iopub.execute_input":"2022-09-12T05:45:08.417188Z","iopub.status.idle":"2022-09-12T05:45:08.431950Z","shell.execute_reply.started":"2022-09-12T05:45:08.417158Z","shell.execute_reply":"2022-09-12T05:45:08.430875Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n         acc       0.98      0.94      0.96        48\n        good       1.00      0.78      0.88         9\n       unacc       0.98      1.00      0.99       112\n       vgood       0.67      1.00      0.80         4\n\n    accuracy                           0.97       173\n   macro avg       0.91      0.93      0.91       173\nweighted avg       0.97      0.97      0.97       173\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}